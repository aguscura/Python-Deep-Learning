{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_mnist_cnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeESuxInUKWmBzc1kgiiXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguscura/Python-Deep-Learning/blob/main/fashion_mnist_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_EdmwtfRQfT6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hacemos un reshape acá abajo de (28,28,1), ya que la CNN espera un tensor 3D.**"
      ],
      "metadata": {
        "id": "RZYw11d9UsEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels) , (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "class_names = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "metadata": {
        "id": "6AnJVUskQmvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954fec40-138c-4c79-d039-61fbb465fa02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbDN1MygYNGZ",
        "outputId": "5e802085-1ca6-4ad2-b9b8-9fa8eeb06114"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (7,7), activation='relu', input_shape=(28,28,1), padding='same'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pW4JnGErUk6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e95e24-5068-4edd-a810-3b27a6d2666c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                401472    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 479,178\n",
            "Trainable params: 479,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANTE\n",
        "\n",
        "SPARSE_CATEGORICAL_CROSSENTROPY  **VS.**  CATEGORICAL_CROSSENTROPY\n",
        "\n",
        "If your Yi's are one-hot encoded, use categorical_crossentropy. Examples (for a 3-class classification): [1,0,0] , [0,1,0], [0,0,1]\n",
        "\n",
        "But if your Yi's are integers, use sparse_categorical_crossentropy. Examples for above 3-class classification problem: [1] , [2], [3]\n",
        "\n",
        "The usage entirely depends on how you load your dataset. One advantage of using sparse categorical cross entropy is it saves time in memory as well as computation because it simply uses a single integer for a class, rather than a whole vector."
      ],
      "metadata": {
        "id": "0Pirr9GjYLSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**El número que aparece abajo de las epochs coincide con la cantidad de imagenes / batch size**\n",
        "\n",
        "Epoch 1/5\n",
        "\n",
        "1/600 --> Esto indica por ejemplo que teniamos 60.000 imagenes y el batch_size fue de 100."
      ],
      "metadata": {
        "id": "J8mLnzhZh9ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics= ['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size = 100)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test Accuracy: ', test_acc )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iptbDIQVWEkG",
        "outputId": "39c33a8e-6f1f-481f-fe9f-5de40212a3d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "600/600 [==============================] - 212s 352ms/step - loss: 0.4668 - accuracy: 0.8322\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 204s 339ms/step - loss: 0.2997 - accuracy: 0.8915\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 203s 338ms/step - loss: 0.2580 - accuracy: 0.9061\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 200s 333ms/step - loss: 0.2266 - accuracy: 0.9173\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 200s 333ms/step - loss: 0.2055 - accuracy: 0.9242\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.2496 - accuracy: 0.9093\n",
            "Test Accuracy:  0.9093000292778015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BatchNormalization** --> Normaliza las entradas de las capas de la red neuronal. Es decir, la entrada de la capa pasa a tener media 0 y desviación 1.\n",
        "\n",
        "**Dropout** --> Valioso contra el overfitting. \"Desactiva\" o \"duerme\" una cierta parte de las neuronas de la capa en cuestion. Las ignora de manera aleatoria. Es decir, las neuronas no son tenidas en cuenta para una determinada iteración."
      ],
      "metadata": {
        "id": "hKDoum945JmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "model_2 = Sequential()\n",
        "model_2.add(Conv2D(filters=32, kernel_size= (3,3), activation='relu', strides=1, padding='same', input_shape=(28,28,1)))\n",
        "model_2.add(BatchNormalization())\n",
        "\n",
        "model_2.add(Conv2D(filters=32, kernel_size= (3,3), activation='relu', strides=1, padding= 'same'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Conv2D(filters=64, kernel_size= (3,3), activation='relu', strides=1, padding='same'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', strides=1, padding='same'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Flatten())\n",
        "\n",
        "model_2.add(Dense(512, activation='relu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.5))\n",
        "\n",
        "model_2.add(Dense(128, activation='relu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.5))\n",
        "\n",
        "model_2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DHd9MY1z7ly",
        "outputId": "572ab75f-d144-490e-a678-8891a999b013"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 28, 28, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 28, 28, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,017,770\n",
            "Trainable params: 13,016,106\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Con BatchNormalization y Dropout\n",
        "\n",
        "model_2.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics= ['accuracy'])\n",
        "\n",
        "model_2.fit(train_images, train_labels, epochs=5, batch_size = 100)\n",
        "\n",
        "test_loss, test_acc = model_2.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test Accuracy: ', test_acc )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1lqNOtE6a3C",
        "outputId": "120be64f-0699-4bc8-87d8-7790070326af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "600/600 [==============================] - 615s 1s/step - loss: 0.5005 - accuracy: 0.8280\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 613s 1s/step - loss: 0.3088 - accuracy: 0.8897\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 616s 1s/step - loss: 0.2583 - accuracy: 0.9071\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 635s 1s/step - loss: 0.2289 - accuracy: 0.9178\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 612s 1s/step - loss: 0.2097 - accuracy: 0.9248\n",
            "313/313 [==============================] - 27s 85ms/step - loss: 0.2173 - accuracy: 0.9202\n",
            "Test Accuracy:  0.920199990272522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aún podemos mejorar el modelo sumando mas **epochs**."
      ],
      "metadata": {
        "id": "j3a5G4CuAIdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECAIMIENTO EN EL RATIO DE APRENDIZAJE**\n",
        "\n",
        "El learning rate es fundamental que se ajuste al momento del entrenamiento. Como vimos, al principio podemos aprender de a pasos \"grandes\", pero luego, a medida que nos acercamos al minimo de la loss-function, lo mejor es dar pasos \"pequeños\" buscando el optimo global.\n",
        "\n",
        "Para esto, existe un callback llamado LearningRateScheduler, que nos permite ir disminuyendo el learning_rate a medida que la red aprende. \n",
        "\n",
        "A este callback tenemos que alimentarlo con una funcion que le indique de que manera va a ir reduciendo el lr. Y va a devolver justamente la tasa de aprendizaje actualizada. "
      ],
      "metadata": {
        "id": "lM2Yoe6-A5lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "#Comenzamos con lr=0.001\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model_2.compile(optimizer=optimizer,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "reduce_lr = callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
        "\n",
        "model_2.fit(train_images, train_labels, epochs=30, callbacks=[reduce_lr])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Accuracy: \", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkCrF-ADAM1u",
        "outputId": "189a2692-c33c-48fb-e739-5efe25058c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            " 139/1875 [=>............................] - ETA: 11:27 - loss: 0.2551 - accuracy: 0.9080"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CallBacks**\n",
        "\n",
        "Un callback permite personalizar el modelo durante el entrenamiento. Es una herramienta muy util. Ej. de callbacks LearningRateScheduler, ModelCheckpoint."
      ],
      "metadata": {
        "id": "pOM7R1LuDrv-"
      }
    }
  ]
}