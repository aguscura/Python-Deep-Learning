{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPG9iRyJQs1pHVt33KLgxhx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguscura/Python-Deep-Learning/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algo que distinque a las redes neuronales convolucionales es que hacen la **suposición de que las entradas son imágenes**. Esto nos permite reconocer elementos concretos en las imágenes."
      ],
      "metadata": {
        "id": "QfacbAWn8S9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dos capas que definen las CNN y puede expresarse como **grupos de neuronas especializadas en 2 operaciones**: *convolución y pooling*"
      ],
      "metadata": {
        "id": "0j2s9L7e8krz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferencia principal entre una capa densamente conectada y una capa convolucional es que la capa densa aprende patrones globales en el espacio global. En cambio, la capa convolucional aprende patrones locales dentro de la imágen en pequeñas ventanas 2D.\n",
        "\n",
        "Lo que hace la **capa convolucional** es detectar features en las imagenes (ojos, boca, nariz). Esto permite que una vez que la red aprende una determinada cosa (ejemplo, cómo es un ojo) puede reconocerlo en cualquier parte de la imagen. En cambio, una red densamente conectada tiene que aprender de nuevo si el ojo (siguiendo el ejemplo) aparece en otro lado. "
      ],
      "metadata": {
        "id": "1OvOo2RV9yad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra cosa interesante de las capas conv. es que pueden aprender jerarquías (desde patrones básicos hasta patrones mucho más complejos). Lo que hace es aprender cosas basicas y despues usa este aprendizaje para generar patrones de mayor complejidad y asi sucesivamente. "
      ],
      "metadata": {
        "id": "Q9Q8xKxF-8SF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas capas usan tensores 3D. Dos ejes se usan para la ubicación en el plano 2D. Un tercer eje se usa para el canal o profundidad (\"depth\"). Este tercer canal puede tener una dimension (blanco y negro) o por ejemplo 3 dimensiones para RGB color."
      ],
      "metadata": {
        "id": "g2dNQ-az_PvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un detalle a remarcar es que **no se conectan TODAS las neuronas de la capa de entrada con TODAS las neuronas de la primer capa oculta** convolucional. ***¡Esto si sucedia en las redes densamente conectadas!***"
      ],
      "metadata": {
        "id": "VNdiQCe_ALWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAS NEURONAS DE LA CAPA DE ENTRADA ALMACENAN LOS PIXELES DE LA IMAGEN."
      ],
      "metadata": {
        "id": "Y1d61Q_fA0wE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entonces, solo una parte de las neuronas de la capa de entrada (es decir, SOLO UNA PARTE DE LA IMAGEN) se conecta con una neurona de la primer capa oculta. Luego, OTRA PARTE DE LA IMAGEN (o sea, otra parte de las neuronas de la capa de entrada) se conecta con OTRA neurona de la capa oculta. Y asi sucesivamente. Por partes."
      ],
      "metadata": {
        "id": "uKKeG2X5IgQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algo importante es que la relacion entre la capa de entrada (la imágen en sí misma) y la primer capa oculta está dada por UNA MATRIZ DE PESOS (W) y una de SESGOS (b). Es necesario destacar que para conectar ambas capas ENTERAS, se usa una UNICA matriz de pesos y una UNICA matriz de sesgos. \n",
        "\n",
        "Es decir, unicas matrices para relacionar las capas completamente. No es que tenemos una matriz de pesos y sesgos para CADA neurona de la capa oculta. Sino que todas las neuronas de la capa oculta usan la misma matriz de pesos y sesgos para relacionarse con la capa de entrada.\n",
        "\n",
        "Esto reduce muchisimo la cantidad de parámetros a entrenar.\n",
        "\n",
        "Las matrices de pesos y sesgos son similares a los filtros de imagenes que usamos con el celular o photoshop. Pero en este caso se usan para buscar patrones o caracteristicas."
      ],
      "metadata": {
        "id": "0cylUd0lI0S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Capa de pooling:** Capa de resumen o agrupación. Sintetiza la información de la capa convolucional. Toma una ventana de la capa convolucional (Ej. 3x3) y la resume en un unico resultado (neurona) en la capa de pooling. Simplificando o resumiendo la red.\n",
        "\n",
        "Existen 2 operaciones muy conocidas para condensar la información. **max-pooling** toma el valor máximo de la ventanita nueva que esta tomando (la de 3x3 en el ejemplo inmediatamente anterior). **avg-pooling** toma el valor promedio de la ventana. Recordar que esta nueva ventana es una porción de neuronas de la capa convolucional y no de la imagen inicial."
      ],
      "metadata": {
        "id": "Dg8B_MAm7jPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algo a destacar es que el max-pooling mantiene la relación de espacio, las proporciones!**\n",
        "\n",
        "**STRIDE - TAMAÑO DEL PASO CON QUE SE DESLIZA LA VENTANITA EN LA CAPA DE CONVOLUCION.**\n",
        "\n",
        "**PADDING - CANTIDAD DE CEROS QUE SE PONEN ALREDEDOR DE LA VENTANITA** "
      ],
      "metadata": {
        "id": "9xEgLEGF_LPc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cLsDAqZ683A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}