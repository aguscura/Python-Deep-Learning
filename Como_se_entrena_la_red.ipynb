{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Como se entrena la red.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmF/0irV4Bws7X6dvPkg0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguscura/Python-Deep-Learning/blob/main/Como_se_entrena_la_red.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Como se entrena una red neuronal**"
      ],
      "metadata": {
        "id": "TTFSKRRscT6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para controlar la salida de una red neuronal, debe poder medirse cuan lejos está la salida de lo que se esperaba. Este es el trabajo de la función de perdida de la red (**loss function**). La funcion de perdida toma las predicciones de la red y el valor real de la etiqueta y calcula un error cometido para una muestra de entrada específica.\n",
        "\n",
        "Este calculo del error sirve como **retroalimentacion** para la red *ajustando los parámetros de manera que el error disminuya gradualmente.*\n",
        "\n",
        "Este **ajuste** es realizado por el **optimizador** que usa esta ***retropropagación*** del error para el ajuste de los parámetros. Esto es clave para el aprendizaje y se denomina \"Backpropagation\"."
      ],
      "metadata": {
        "id": "1q8l5OaOcZpr"
      }
    }
  ]
}