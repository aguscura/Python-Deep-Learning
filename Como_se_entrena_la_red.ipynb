{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Como se entrena la red.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPffiD74wL3vyCmguOQFWks",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguscura/Python-Deep-Learning/blob/main/Como_se_entrena_la_red.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Como se entrena una red neuronal**"
      ],
      "metadata": {
        "id": "TTFSKRRscT6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para controlar la salida de una red neuronal, debe poder medirse cuan lejos está la salida de lo que se esperaba. Este es el trabajo de la función de perdida de la red (**loss function**). La funcion de perdida toma las predicciones de la red y el valor real de la etiqueta y calcula un error cometido para una muestra de entrada específica.\n",
        "\n",
        "Este calculo del error sirve como **retroalimentacion** para la red *ajustando los parámetros de manera que el error disminuya gradualmente.*\n",
        "\n",
        "Este **ajuste** es realizado por el **optimizador** que usa esta ***retropropagación*** del error para el ajuste de los parámetros. Esto es clave para el aprendizaje y se denomina \"Backpropagation\"."
      ],
      "metadata": {
        "id": "1q8l5OaOcZpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forward propagation y back propagation**\n",
        "\n",
        "*Forward propagation: * Se da cuando los datos de entrada cruzan toda la red en el camino de ida. Estos inputs son afectados por los parámetros de la red (pesos y sesgos) para calcular las supuestas etiquetas (labels) de cada imágen.\n",
        "\n",
        "Luego, se calcula el error a traves de la función de perdida, interviene el optimizador para ir disminuyendo ese error, se ajustan los pesos en un proceso de retroalimentación llamado *backward propagation*.\n",
        "\n",
        "*Algo importante a tener en cuenta es que las neuronas de cada capa solo reciben una fracción de la señal total de error. Esta fracción se basa en la contribución relativa que haya aportado cada neurona a la salida original. Esto se repite hacia atras capa por capa hasta que las neuronas de todas las capas de la red hayan recibido una señal del error cometido.* A esto se le llama **diferenciación simbolica**."
      ],
      "metadata": {
        "id": "y_8DXeQF7iB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El optimizador usa una técnica llamada **Gradient Descent** la cual va cambiando los pesos en pequeños incrementos calculando la derivada de la funcion de perdida. Esto nos permite ver en que direccion debemos movernos para llegar al minimo global."
      ],
      "metadata": {
        "id": "TeLVYZe485st"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent"
      ],
      "metadata": {
        "id": "nG2_M_FK-qZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que la derivada, el gradiente representa la pendiente de la recta tangente a la gráfica de una función. Más precisamente, el gradiente apunta a los puntos de la gráfica a los cuales la gráfica **tiene un mayor incremento**. La magnitud del gradiente es la pendiente de la gráfica en esa dirección."
      ],
      "metadata": {
        "id": "tBPVV7BcBY2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cada iteración, **cada neurona** obtiene el valor del gradiente de la funcion de perdida que le corresponde. Luego, se actualizan los valores en la dirección opuesta al gradiente. Esto se da ya que el gradiente apunta en la dirección de max. crecimiento de la función de perdida. Por lo tanto, al hacer el negativo del gradiente, estamos yendo en la dirección de max. decrecimiento y por lo tanto disminuimos el error."
      ],
      "metadata": {
        "id": "PksB_dWFCGe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tipos de Gradient Descent"
      ],
      "metadata": {
        "id": "DKwEv9NZE84H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stochastic Gradient Descent (SGD)** = Se da cuando el gradiente se estima a partir del error observado **muestra a muestra** (imagen a imagen). Estocástico se refiere a \"aleatorio\" (son sinónimos). Es decir, cada imágen se selecciona aleatoriamente.\n",
        "\n",
        "**Batch Gradient Descent (BGD)** = Se da cuando usamos todo el conjunto de datos de entrenamiento en cada paso del algoritmo de optimización.\n",
        "\n",
        "**Mini Batch Gradient Descent (MBGD)** = Es un paso intermedio. No se toma de a una sola imágen ni tampoco el conjunto de entrenamiento entero. Se toma un batch de tamaño determinado para calcular el gradiente y disminuir el error. "
      ],
      "metadata": {
        "id": "TFHXEyEUZMlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importante.**\n",
        "\"Lote\" puede hacer referencia a TODO el conjunto de datos de entrenamiento. Donde el primer lote es la primera pasada, **pero** siempre haciendo referencia a TODO el set de entrenamiento.\n",
        "\n",
        "En este caso, estamos usando \"Lote\" como UNA PARTE de esos datos de entrenamiento. Dividimos el set en varios lotes, y usamos cada uno de esos \"mini lotes\" para calcular el gradiente e iterar con un nuevo \"mini lote\"."
      ],
      "metadata": {
        "id": "GmaWkG1AawTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, concluimos que el mejor metodo es el MBGD. ¿Como funciona entonces?\n",
        "Dividimos el set de entrenamiento en batches (batch_size). Entonces en lugar de usar el set completo, ej. 1000 imágenes, tomamos el primer batch, ej. 100 imagenes, y usamos un Stochastic Gradient Descent (imágen a imágen) sobre esas 100. Tenemos el valor del gradiente de la función de pérdida, tenemos el sentido en el que tenemos que mover los parámetros para reducir el error, cambiamos esos parámetros y despues volvemos a iterar sobre las siguientes 100. ¿Cúantas veces vamos a pasar el set completo de entrenamiento por la red? Eso lo definen las **epochs**."
      ],
      "metadata": {
        "id": "c9iTBlo2bO4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Función de pérdida"
      ],
      "metadata": {
        "id": "oe4qgBBNcbk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puede llamarse tambien funcion de coste (cost function). Si nos ponemos estrictos, en la literatura el termino \"perdida\" se refiere a la perdida medida para UN SOLO PUNTO de datos; en cambio, el termino \"coste\" se refiere a la pérdida en todo el conjunto de datos (promedio o sumada)."
      ],
      "metadata": {
        "id": "magKgDTUczEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**\n",
        "\n",
        "Para elegir bien la funcion de pérdida debemos ver si el problema es de REGRESIÓN Ó CLASIFICACIÓN.\n",
        "\n",
        "También es importante la función de activación de la CAPA DE SALIDA. Debe ser apropiada con la función de perdida elegida."
      ],
      "metadata": {
        "id": "xr4Yme5mvHre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*categorical_crossentropy* --> Para problemas de clasificacion, donde tenemos una salida en formato categorico. En general, se usa esta funcion de perdida cuando tenemos un problema de clasificacion de varias clases. **Importante**: Tiene que haber el mismo numero de neuronas en la ultima capa que de clases. Y en este caso, además, la salida de la ultima capa debe pasar a través de la función de activación \"**softmax**\" para que cada nodo genere una probabilidad entre 0 y 1. Y la suma de todas las probabilidades sea igual a 1. \n",
        "\n",
        "*binary_crossentropy* --> Idem la anterior pero para problemas de clasificacion binaria. Si usamos esta funcion de perdida, solo necesitamos UNA neurona en la salida para clasificar los datos en 2 clases. El valor de salida se activa con una función de activación **sigmoid** y el rango de salida estará entre 0 y 1.\n",
        "\n",
        "*mean_squared_error* --> Función de activación para problemas de regresión. Se calcula tomando la media de las diferencias al cuadrado entre el valor real y el predicho. NO SE USA FUNCIÓN DE ACTIVACIÓN EN LA ULTIMA CAPA."
      ],
      "metadata": {
        "id": "KxVOXUi3vcFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizadores"
      ],
      "metadata": {
        "id": "TKTx8hbNv2h6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD, RMSprop, AdaGrad, Adadelta, Adam, Adamax, Nadam."
      ],
      "metadata": {
        "id": "R3atjF6KylQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El SGD busca disminuir la funcion de perdida tomando el negativo del gradiente, o sea la dirección de máximo decrecimiento. Pero lo hace buscando un minimo local, de la neurona que está analizando. En cambio AdaGrad mueve los parámetros para disminuir la funcion de perdida NO NECESARIAMENTE EN LA DIRECCIÓN DE MAXIMO DECRECIMIENTO DE LA LOSS **DE LA NEURONA**, es decir, no en la direccion del negativo del gradiente; PERO SÍ BUSCA LLEGAR AL **OPTIMO GLOBAL** por lo que en problemas multi dimensionales, conviene su uso. Pero a su vez, AdaGrad tiene riesgo de no llegar nunca a ese optimo global."
      ],
      "metadata": {
        "id": "L-LHi3JVy103"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSprop vino a solucionar este problema de AdaGrad de no llegar al optimo global y funciona muy bien (excepto en problemas muy sencillos). Era el optimizador preferido hasta que salió **Adam**."
      ],
      "metadata": {
        "id": "mRITBAQnzqBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algo importante es que los optimizadores tienen distintos hiperparametros que podemos tunear antes de entrenar el modelo. Para eso, nos creamos directamente nuestro optimizador personalizado y desp lo usamos en el metodo compile. \n",
        "\n",
        "**-Creo optimizador y tuneo su learning_rate**\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "my_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "**-Se lo paso al modelo**\n",
        "\n",
        "model.compile(optimizer = my_optimizer,\n",
        "              loss = 'binary_crossentropy\",\n",
        "              metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "L80e21wN0Ln6"
      }
    }
  ]
}