{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parametros-e-Hiperparametros.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPT069O7RdAnQVy7fHFTThl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguscura/Python-Deep-Learning/blob/main/Parametros_e_Hiperparametros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parámetros** --> Son internos a la red neuronal. Por ejemplo los pesos de las neuronas. Se aprenden automáticamente a partir de los datos de entrenamiento. Estos, son los mismos parametros que luego se usan en producción para hacer predicciones.\n",
        "\n",
        "**Hiperparámetros** --> Son externos a la red y los determina el programador. Ejemplo tamaño del batch, funciones de activación posibles, epochs, learning_rate, etc.\n",
        "\n",
        "Es importante aclarar que hoy en día ya hay propuestas para que un algoritmo busque directamente los hiperparámetros optimos por nosotros. Ejemplos **HyperOpt, KOpt, Talos, GPflowOpt**. Y en el cloud computing, Google Cloud. "
      ],
      "metadata": {
        "id": "C4FErHpd3i_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dos grandes grupos:\n",
        "\n",
        "Hiperparámetros a nivel **estructura y topologia** de la red: Número de capas, número de neuronas por capa, funciones de activación, inicialización de los pesos.\n",
        "\n",
        "Hiperparámetros a nivel de algoritmo de **aprendizaje**: Learning rate, epochs, batch size, momentum, etc."
      ],
      "metadata": {
        "id": "vZr8RfdN4ZCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hiperparámetros relacionados con el aprendizaje\n",
        "\n",
        "**Epochs**\n",
        "\n",
        "Numero de veces que los datos de entrenamiento han pasado por la red neuronal. Un numero en exceso de epochs hace que el modelo se ajuste en exceso a los datos (overfitting) lo que genera problemas de generalización (se le complica cuando ve algo nuevo despues. También un número excesivo de epochs puede causar problemas de vanishing gradients y exploding gradient.\n",
        "En cambio, un numero menor al optimo de epochs puede hacer que el modelo no aprenda lo suficiente.\n",
        "\n",
        "Una buena practica es ir aumentando las epochs hasta que la presición con los datos de validación empiece a decrecer (aún cuando la presicion con los datos de entrenamiento siga mejorando).\n"
      ],
      "metadata": {
        "id": "cEV4XdvM412i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Rate**\n",
        "\n",
        "Es un escalar que se usa para multiplicar la magnitud del gradiente. Este escalar es menor a 1, entonces esto genera que nos movamos de a pasos cortos. Es decir, en lugar de ajustar los parámetros del modelo en la magnitud del gradiente, los ajustaremos en la magnitud del gradiente **afectado por el learning rate**, que al ser un numero menor que 1, disminuye el impacto de este cambio.\n",
        "\n",
        "**Learning Rate Decay** \n",
        "\n",
        "Es un buen hiperparámetro. Lo que hace es ir disminuyendo el Learning Rate a medida que pasan las Epochs. Entonces, al principio, podemos usar learning rates altos. Para converger más rapido a valores bajos de error. Una vez que nos encontramos en la zona de errores más bajos, el learning rate se va haciendo más chico para dar pasitos cortos y que las posibilidades de encontrar el minimo local aumenten.\n",
        "\n",
        "DATOS\n",
        "\n",
        "Para optimizador **sgd** learning rate que funciona bien 0.1\n",
        "\n",
        "Para optimizador **Adam** learning rate que funciona bien está entre 0.001 y 0.01."
      ],
      "metadata": {
        "id": "CbjZ0eYW6k4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Momentum**\n",
        "\n",
        "Soluciona el problema de los minimos locales vs. los minimos globales. Una funcion de Error vs. Parámetros puede ser compleja y tener un minimo local, en donde, al llegar, el gradiente se hace 0. Esa parece ser la solucion optima, pero en realidad llegaste a un minimo local y no a uno global.\n",
        "\n",
        "Entonces, cual es nuestro problema? Que en un minimo local, al llegar a la curva donde la pendiente es 0, el gradiente es 0. Y ahi para de aprender. \n",
        "\n",
        "Entonces momentum lo que hace es tomar una ponderación de los ultimos gradientes. Más alla de que el ULTIMO gradiente sea practicamente 0 (porque estamos en un minimo local) no vamos a tomar solo este gradiente; sino que vamos a tomar los ultimos. Y vamos a ponderarlos. Este gradiente ponderado se va a usar para seguir aprendiendo. \n",
        "\n",
        "Momentum es el factor numerico que se usa para ponderar los gradientes.\n",
        "\n",
        "Nesterov momentum es muy popular y lo que hace es ralentizar el gradiente cuando ya esta cerca de la solución.\n",
        "\n",
        "Ej:\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)."
      ],
      "metadata": {
        "id": "iqE6oWscL4NU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inicializacion de los pesos de las neuronas**\n",
        "\n",
        "Es una buena practica que todas las neuronas comiencen con parametros aleatorios y que todas las neuronas tengan distintos parametros iniciales. Esto rompe la simetria entre neuronas, ya que si dos neuronas se inician con exactamente los mismos parametros, tendran siempre el mismo gradiente a lo largo de todo el entrenamiento. Esa simetria se seguiria dando a lo largo de todas las iteraciones siguientes por lo que no seran capaces de aprender caracteristicas diferentes.\n",
        "\n",
        "Inicializarlos aleatoriamente siguiendo una normal estandar está ok, pero puede traer problemas de vanishing gradients o exploding gradients."
      ],
      "metadata": {
        "id": "GWR3cfglsmDF"
      }
    }
  ]
}